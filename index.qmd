---
title: "AI-ducation"
subtitle: "The good, the bad and the bot-tastic"
author: 
  - name: Gerko Vink
    orcid: 0000-0001-9767-1924
date: 18 Jun 2024
date-format: "D MMM YYYY"
format: 
  revealjs:
    theme: [solarized, gerko.scss]
    progress: true
    multiplex: true
    transition: fade
    slide-number: true
    margin: 0.075
    logo: "logoUU.png" 
    toc: false
    toc-depth: 1
    toc-title: Outline
    scrollable: false
    reference-location: margin
    footer: Gerko Vink  - Methods & Statistics @ UU
    bibliography: references.bib
editor: source
---

## Disclaimer
This presentation is a collection of my thoughts and opinions. It does not necessarily represent the views of Utrecht University or the USO Consortium AI in Higher Education.

These materials are generated by Gerko Vink, who holds the copyright. The intellectual property belongs to Utrecht University. Images are either directly linked, or generated with DALL-E. That said, there is no information in this presentation that exceeds legal use of copyright materials in academic settings, or that should not be part of the public domain. 

::: {.callout-warning}
You **may use** any and all content in this presentation - including my name - and submit it as input to generative AI tools, with the following **exception**:

- You must ensure that the content is not used for further training of the model
:::
Source:

- [www.gerkovink.com/fsw60y](https://www.gerkovink.com/fsw60y)
- [github.com/gerkovink/fsw60y](https://github.com/gerkovink/fsw60y)

## First of all
::: {.callout-tip}
## Education is a universal right
<q>*Everyone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit*</q> <br><br>
Source: [Universal Declaration of Human Rights](https://www.un.org/sites/un2.un.org/files/2021/03/udhr.pdf) as declared by the United Nations in 1948.
:::

# Introduction to gen AI

## What is Generative AI?

**Generative AI** refers to a subset of artificial intelligence technologies capable of generating new content, ideas, or data that resemble human-like outputs. 

  - Generative AI operates through advanced machine learning models, particularly deep learning networks. 
  - These models are trained on large amounts of data in a specific domain (e.g., text, images, video) and can then generate new outputs based on the patterns and features they have learned.

Some common examples of generative AI technologies include:

- Chatbots and virtual tutors: AI-driven chatbots can provide personalized tutoring, answering student questions and offering explanations on a wide range of subjects.

- Content creation tools: Tools like GPT (Generative Pre-trained Transformer) can assist in creating educational content, generating lecture notes, or drafting exam questions based on certain criteria.

- Automated essay scoring and feedback: AI models can grade essays and provide feedback to students on their writing.

## What is generative AI?

![](img/gpt1.png)

## What does it think it looks like?

![](img/gpt2.png)

## What does it think it looks like?

![](img/gpt3.png)

## Does it think it is smart?
![](img/gpt4.png)

## No need for humans, then?

![](img/gpt5.png)

## What does this tell us?


## What about other AI tools?

![](img/sdf1.png)

## With a bit of replication

![](img/sdf2.png) 

## And hallucination

![](img/sdf3.png)

## How Do AI Tools Work (in 10 steps)?

1. Machine learning enables computers to learn from data, identify patterns, and make decisions with varying levels of human intervention.
2. Machine learning methods often work by means of training, for example to perform a single task or set of tasks.
3. Some forms of models are not specifically programmed to perform certain tasks and learn withouth human intervention. 
4. The domain of machine learning that focuses on such human brain-like deep learning strategies is called neural networks (NNs).
5. Transformers ([Vaswani et al. 2017](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)) are a type of neural network that have advanced deep learning, particularly in the domain of natural language processing.
6. Instead of modeling words one after another, transformers can look at whole sentences or paragraphs at once and take the context of text into account. 
7. It is not hard to imagine that contextual understanding allows for better learning and more flexible applications.

::: {.footer}
[Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017).<br>Attention is all you need. Advances in neural information processing systems, 30.](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
:::

## How Do AI Tools Work (in 10 steps)?
::: {.columns}
::: {.column width="60%"}
<br>

8. Generative AI tools, such as Gemini, chatGPT or GitHub Copilot are applications of transformers.
9. These tools have been trained on extremely large amounts of data (mostly text) and have learned from the structure, meaning and nuances of the language.
10. After training, these tools can generate new text that both coherent an contextually relevant.
<br><br>
Don't be fooled! It's just a prediction model
:::
::: {.column width="40%"}
<br>
![](img/ai_train.webp){width="100%"}
:::
:::

::: {.footer}
Image prompt: *generate an image of an AI in android form training with weights in a gym*
:::


## Who develops generative AI tools

- Generative AI technologies are often developed by publicly traded companies with:
    - Deep pockets
    - Shareholders
    - Motives and goals that may diverge from academic or public interests

- These technologies also require significant computing resources for training and operation
  - This skews access and development to those with substantial resources.
  - If you feel sad or overwhelmed by the low sense of control, read [Choose Your Weapon:
Survival Strategies for Depressed AI Academics](https://ieeexplore.ieee.org/abstract/document/10458714)

::: {.footer}
Togelius, J., & Yannakakis, G. N. (2024). Choose Your Weapon: Survival Strategies for Depressed AI Academics [Point of View]. Proceedings of the IEEE, 112(1), 4-11.
:::
  
# Impact of generative AI

## Impact on education

There is a finite number of options for dealing with generative AI in education. These options translate to the following *stages of AI grief*:

::: {.columns}
::: {.column width="50%"}
1. **Ignore** the existence of generative AI
2. **Forbid** the use of generative AI
3. **Circumnavigate** generative AI by using offline assessment modes like pen/paper exams or oral exams
4. **Test around** Let students perform tasks that generative AI struggles with
5. **Embrace** generative AI and allow it in course work
6. **Rethink** the way we assess students and develop new assessment methodologies
:::
::: {.column width="50%"}
![](https://respage.com/wp-content/uploads/2022/01/Why-Human-and-AI-Leasing-Agents-Need-Each-Other-to-Deliver-Excellent-Customer-Service-to-Prospects-1024x683.png){width="100%"}
:::
:::

## Futureproof education?
::: {.callout-important appearance="simple"}
# Could it be
That our defined learning goals, our evaluations and the skills that we teach are not aligned with the future professional needs for our student body?
:::

## Impact of AI on Cognitive Performance

![](img/cogn1.png)

::: {.footer}
[Heersmink, R. Use of large language models might affect our cognitive skills. Nat Hum Behav (2024)](https://doi.org/10.1038/s41562-024-01859-y)
:::

## Impact of AI on Cognitive Performance
::: {.columns}
::: {.column width="50%"}
![](img/cogn4.png)
:::
::: {.column width="50%"}
![](img/balance.webp)
:::
:::

::: {.footer}
[Habib, S., Vogel, T., Anli, X., & Thorne, E. (2024). How does generative artificial intelligence impact student creativity?. Journal of Creativity, 34(1), 100072.](https://doi.org/10.1016/j.yjoc.2023.100072)
:::

## Impact of AI on cognitive performance
![](img/cogn2.png)
![](img/cogn3.png)

::: {.footer}
[Abbas, M., Jam, F.A. & Khan, T.I. Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students. <br> Int J Educ Technol High Educ 21, 10 (2024).]( https://doi.org/10.1186/s41239-024-00444-7)
:::

## Ethical impact

Many people are unaware of the ethical implications of using AI tools, apart from presenting AI-generated work as your own product. 

1. AI tools are often trained on data that is biased or incomplete, which can lead to biased or incorrect results. 
2. AI tools have demonstrated to yield inaccurate, incomplete or false information. 
  - This can happen when the AI tool perceives patterns or objects that are nonexistent, resulting in nonsensical or inaccurate output, often referred to as hallucinations [@ziwei; @alkaissi2023artificial; @athaluri2023exploring].
  - Some resistance against the term hallucinations has emerged [@Ostergaard2023]. 

It is important to always use multiple sources to verify any bit of information. As a user of AI tools you should accept that **only you are responsible** for using, interpreting and curating AI-generated output. 

The age-old adage garbage in, garbage out holds here too: old biases and ideas may unwantedly be perpetuated by AI tools, thereby fueling divides, biases and stereotypes that we have tried so hard to remove.

## Legal impact
AI tools are often trained on data that is copyrighted or patented, which can lead to legal issues if the data is used without permission. To avoid such issues, when interacting with AI tools, users should protect intellectual property rights and copyright. 

When submitting prompts as **input to AI tools** it is important to ensure that

- you are allowed to share the information in the prompt or have explicit permission
- you are not infringing on any right associated with the information in the prompt

Likewise, it is important to realize that no intellectual property or copyright may be infringed with using the **output of the AI tool**. The training of the AI tool happened on a large set of data; some of that data may have been used illegitimately. By using AI generated output you may plagiarize existing work or otherwise infringe on intellectual property rights.

This is a tricky scenario, as the nontransparent training of AI tools makes it challenging to prove that no IP is infringed with the realized output. However, one could argue that embedding AI tools in a normal scientific knowledge discovery scenario would minimize the change of any infringement. Such a route would result in a process where information from multiple sources is processed and curated by an actual human.

## Environmental impact
Are you aware of the impact that contemporary AI tools may have on the environment?

- Together with e.g. cloud storage and e-mail traffic, AI tools constitute a *hidden carbon footprint* that often escapes our awareness. 

While it is not as apparent as airline travel, the impact of using AI tools may be far greater than you think! 

- Decarbonizing the energy usage alone is not enough to sustainably implement AI tools in our everyday life [@berthelot2023]. 
- Using generative AI Tools has been estimated to account for up to 25 times the energy emissions that are generated from training the models [@chien2023]. 

While the environmental impact can ultimately be significantly lowered by moving from server-based generative AI to on-chip generative AI, there will always be a cost of using AI tools. 

<!-- Many people have thought about how AI will impact human life and Hollywood has monetized its threat to human existence. Not many may have realized that our lives may currently be at risk through AI-induced global warming. -->


## Social impact
In recent years many idealistic promises have been made about the potential of AI to improve human life. 

- Widespread access for everyone to AI models and tools has been said to contribute to equality, allowing everybody to access high quality information and interact witht the same technology. 
- AI tools are neutral and can be used to harm people and spread misinformation. 
- AI tools can be used to manipulate people, to deepen existing biases, to incite hate speech or to discriminate against people, evidence of which has been found in the use of AI tools in hiring processes and the potential for election manipulation [@baldassarre2023; @lyttonAIHiringTools2024; @aliswensonElectionDisinformationTakes2024; @mekelapanditharatneHowAIPuts2023]. 

Aside from the potential for AI to incite societal harm on a fundamental level, it can also disrupt society on a more existential level. The widespread use of AI tools may lead to a loss of jobs, as AI tools can automate tasks that were previously done by humans. This can lead to a loss of income and a decrease in the quality of life for many people. 

The zeitgeist of contemporary AI tools pairs a strong call for regulatory action with a warning for over-regulation. 

## Human rights and labor rights
There is [evidence](https://time.com/6247678/openai-chatgpt-kenya-workers/) that the workers who curate these models are treated unfairly or even inhumanely by their employers. 

- This [interview](https://blogs.lse.ac.uk/businessreview/2024/03/25/madhumita-murgia-ai-can-do-harm-when-people-dont-have-a-voice/) also paints a good picture of how and where AI work can harm people. 

This means that the use of AI tools may not only effect the networks of the people who use them, but also have an effect on the people who curate the models behind these tools. 

## So far: Impact on society

- Ethical impact
- Legal impact
- Environmental impact
- Social impact
- Human rights and labor rights
- The Dunning-Kruger effect

![](https://s3.ap-southeast-2.amazonaws.com/assets.the-resilience-shield/app/uploads/2021/05/11143616/Mt-Stupid-1.png)

# How to proceed

## Opinion

::: {.callout-warning}
The rapid rise of key technologies creates friction in our current societal structures, norms and expectations. 

We need to move towards a more sustainable way of living together with *other* forms of intelligence. 

This requires joint experimentation from academia, society, industry and government.
:::

## Towards responsible genAI use
I believe that we should demand from the scientific community to follow these simple steps when using generative AI tools:

1. Minimize the use of AI tools, as they are (currently) environmentally unfriendly
2. Don't input confidential or personal information
3. Don't input information that violates IP or copyright
4. Don't violate IP with using output from the tool
5. Confirm the output accuracy
6. Check the tool output for bias
7. Disclose the use of AI tools in your work
8. Don't do naughty or unjust things with AI tools
9. Ask the tool not to use input for training
10. Open the content you produce by using AI tools as much as possible with permissive licenses

If in doubt about any of the above, don't use generative AI tools.

For teachers: Put a disclaimer on your materials that governs what is or is not allowed when using generative AI tools.

# Inputting student data into AI

## Is It a Good Idea to Use AI in Grading?

![](img/grade.png)

::: {.footer}
[Kumar, R. Faculty membersâ€™ use of artificial intelligence to grade student papers: a case of implications. Int J Educ Integr 19, 9 (2023)](https://doi.org/10.1007/s40979-023-00130-7)
:::

## Student rights in the AI-Era Classroom

::: {.callout-tip}
## Human contact is a right
Every student has the right to be educated and graded by a human being. That right also includes the right to know a priori to what extend AI is used 

1. in creating the educational materials, 
2. in providing feedback,
3. in grading student work.

Every student has the right to refuse interaction or any other involvement with an AI for their coursework.
:::

## Conclusion

Minimize the use of AI tools, and when you do use them, do so responsibly. 

Generative AI can be a great companion in a knowledge discovery journey, but it is not a replacement for scientific rigor, active reading, critical thinking and human creativity. 

Contemporary AI should always be viewed as a complement to human actions rather than a replacement. 

Be as transparant about the use of AI tools in your work as you would require others to be. Also, make sure that you are not violating any rights or laws. 

::: {.callout-note appearance="simple"}
The only way to sustainable embedding of generative AI in academia is to ensure a sense of community and collective ownership of responsible AI practice. 

This requires a shared responsibility that requires the active participation of all involved, whereby we hold ourselves and each other accountable for our actions.
:::

## USO Consortium at Utrecht University
![](img/cons.png)

## References




